{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc95b8c0-6443-475b-990c-485b4d6a6d2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Spark RAPIDS - Value Indexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f1e083-12d1-4228-9db9-8e1af0d7086e",
   "metadata": {},
   "source": [
    "### Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2ee973-e69e-4bfc-baf1-e612832d6247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.234.186:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fb3663313a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505b0ac0-30a7-47dc-a34d-188dd52c352a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RAPIDS Plugin Version Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96888712-ccf8-4244-b51b-d6629e680abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '22.06.0-SNAPSHOT', 'user': 'gshegalov', 'url': 'https://github.com/NVIDIA/spark-rapids.git', 'date': '2022-04-07T21:31:51Z', 'revision': '4a45c5dbefdc7e520d873ee9961fd42850418ce5', 'cudf_version': '22.06.0-SNAPSHOT', 'branch': 'branch-22.06'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._jvm.com.nvidia.spark.rapids.RapidsPluginUtils\\\n",
    "    .loadProps('rapids4spark-version-info.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64b3cbf8-f64d-4c06-8600-4a7f9379807b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'version': '22.06.0-SNAPSHOT', 'user': '', 'date': '2022-04-07T06:18:21Z', 'revision': 'acc42a849a5960079123bc2c76b8269f3d0733c9', 'branch': 'devtools-build-in-docker-for-native'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark._jvm.com.nvidia.spark.rapids.RapidsPluginUtils\\\n",
    "    .loadProps('cudf-java-version-info.properties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "524c45bc-fa08-4c5e-b649-ad076fac9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "spark.conf.set('spark.rapids.sql.explain', 'ALL')\n",
    "spark.conf.set('spark.sql.adaptive.enabled', False)\n",
    "spark.conf.set('spark.rapids.sql.enabled', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6363bcd-2096-447e-9bde-b0165a73adab",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22534143-f505-4abc-ac28-ef38ee82ab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        ['aaa',],\n",
    "        ['a'], \n",
    "        ['bb'],\n",
    "        ['a'],\n",
    "        ['aaa'],\n",
    "    ],\n",
    "    'c1 string'\n",
    ")\n",
    "\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "df6f1488-be84-4b9b-93ca-22af4a1828e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/09 00:34:58 WARN GpuOverrides: \n",
      "*Exec <CollectLimitExec> will run on GPU\n",
      "  *Partitioning <SinglePartition$> will run on GPU\n",
      "  ! <RDDScanExec> cannot run on GPU because GPU does not currently support the operator class org.apache.spark.sql.execution.RDDScanExec\n",
      "    @Expression <AttributeReference> c1#111 could run on GPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| c1|\n",
      "+---+\n",
      "|aaa|\n",
      "|  a|\n",
      "| bb|\n",
      "|  a|\n",
      "|aaa|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6450c8e1-c0f5-49b1-bf84-5a23a2f87b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df\\\n",
    "    .distinct()\\\n",
    "    .orderBy('c1') \\\n",
    "    .withColumn('idx', \n",
    "                row_number().over(\n",
    "                    Window.orderBy(monotonically_increasing_id())\n",
    "                )\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "32af8e75-1095-4889-82e5-f816ae29aa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/09 00:44:07 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/04/09 00:44:07 WARN GpuOverrides: \n",
      "*Exec <CollectLimitExec> will run on GPU\n",
      "  *Partitioning <SinglePartition$> will run on GPU\n",
      "  *Exec <ProjectExec> will run on GPU\n",
      "    *Expression <Alias> cast(idx#119 as string) AS idx#260 will run on GPU\n",
      "      *Expression <Cast> cast(idx#119 as string) will run on GPU\n",
      "    *Exec <SortMergeJoinExec> will run on GPU\n",
      "      #Exec <SortExec> could run on GPU but is going to be removed because replacing sortMergeJoin with shuffleHashJoin\n",
      "        #Expression <SortOrder> c1#111 ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\n",
      "        *Exec <ShuffleExchangeExec> will run on GPU\n",
      "          *Partitioning <HashPartitioning> will run on GPU\n",
      "          *Exec <FilterExec> will run on GPU\n",
      "            *Expression <IsNotNull> isnotnull(c1#111) will run on GPU\n",
      "            ! <RDDScanExec> cannot run on GPU because GPU does not currently support the operator class org.apache.spark.sql.execution.RDDScanExec\n",
      "              @Expression <AttributeReference> c1#111 could run on GPU\n",
      "      #Exec <SortExec> could run on GPU but is going to be removed because replacing sortMergeJoin with shuffleHashJoin\n",
      "        #Expression <SortOrder> c1#248 ASC NULLS FIRST could run on GPU but is going to be removed because parent plan is removed\n",
      "        *Exec <ShuffleExchangeExec> will run on GPU\n",
      "          *Partitioning <HashPartitioning> will run on GPU\n",
      "          *Exec <ProjectExec> will run on GPU\n",
      "            *Exec <FilterExec> will run on GPU\n",
      "              *Expression <IsNotNull> isnotnull(c1#248) will run on GPU\n",
      "              *Exec <WindowExec> will run on GPU\n",
      "                *Expression <Alias> row_number() windowspecdefinition(_w0#120L ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS idx#119 will run on GPU\n",
      "                  *Expression <WindowExpression> row_number() windowspecdefinition(_w0#120L ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) will run on GPU\n",
      "                    *Expression <RowNumber> row_number() will run on GPU\n",
      "                    *Expression <WindowSpecDefinition> windowspecdefinition(_w0#120L ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) will run on GPU\n",
      "                      *Expression <SortOrder> _w0#120L ASC NULLS FIRST will run on GPU\n",
      "                      *Expression <SpecifiedWindowFrame> specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$()) will run on GPU\n",
      "                        *Expression <UnboundedPreceding$> unboundedpreceding$() will run on GPU\n",
      "                        *Expression <CurrentRow$> currentrow$() will run on GPU\n",
      "                *Expression <SortOrder> _w0#120L ASC NULLS FIRST will run on GPU\n",
      "                *Exec <SortExec> will run on GPU\n",
      "                  *Expression <SortOrder> _w0#120L ASC NULLS FIRST will run on GPU\n",
      "                  *Exec <ShuffleExchangeExec> will run on GPU\n",
      "                    *Partitioning <SinglePartition$> will run on GPU\n",
      "                    *Exec <ProjectExec> will run on GPU\n",
      "                      *Expression <Alias> monotonically_increasing_id() AS _w0#120L will run on GPU\n",
      "                        *Expression <MonotonicallyIncreasingID> monotonically_increasing_id() will run on GPU\n",
      "                      *Exec <SortExec> will run on GPU\n",
      "                        *Expression <SortOrder> c1#248 ASC NULLS FIRST will run on GPU\n",
      "                        *Exec <ShuffleExchangeExec> will run on GPU\n",
      "                          *Partitioning <RangePartitioning> will run on GPU\n",
      "                            *Expression <SortOrder> c1#248 ASC NULLS FIRST will run on GPU\n",
      "                          *Exec <HashAggregateExec> will run on GPU\n",
      "                            *Exec <ShuffleExchangeExec> will run on GPU\n",
      "                              *Partitioning <HashPartitioning> will run on GPU\n",
      "                              *Exec <HashAggregateExec> will run on GPU\n",
      "                                ! <RDDScanExec> cannot run on GPU because GPU does not currently support the operator class org.apache.spark.sql.execution.RDDScanExec\n",
      "                                  @Expression <AttributeReference> c1#248 could run on GPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| c1|idx|\n",
      "+---+---+\n",
      "|aaa|  2|\n",
      "|aaa|  2|\n",
      "| bb|  3|\n",
      "|  a|  1|\n",
      "|  a|  1|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.alias('a').join(df1.alias('b'), df.c1 == df1.c1).selectExpr('a.c1', 'b.idx').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f593ff-b071-4a6c-a3db-2eb86454d0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
